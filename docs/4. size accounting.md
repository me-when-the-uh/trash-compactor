# Size Accounting

Trash-compactor tracks data volume before and after compression, differentiating between logical file size (application view) and on-disk compressed size (NTFS storage). These metrics drive summaries, dry-run projections, and entropy reports.

## Logical vs. compressed size

"Original" size refers to the logical file size reported by `Path.stat().st_size`. This value matches what Windows displays in file properties and remains constant regardless of NTFS compression.

Compressed size is retrieved via the NTFS API. The `get_ntfs_compressed_size` function in `src/file_utils.py` calls `GetCompressedFileSizeW` through `ctypes` to determine the actual bytes used on disk, accounting for cluster rounding. This value confirms compression success and allows calculation of space savings.

The `is_file_compressed` function in `src/file_utils.py` compares these two values. A file is considered compressed if its on-disk size is smaller than its logical size. When sizes are equal, the function may query `compact.exe` in thorough mode for verification.

## Dry-run projections

In dry-run mode, the program projects potential savings without modifying files. Entropy sampling collects data per directory, including file counts, total logical size, and estimated savings based on zlib compression.

Each directory's data is stored in an `EntropySampleRecord` defined in `src/stats.py`. For per-directory reporting, this record tracks the total logical size of the subtree, the number of bytes actually inspected, and the projected reduction percentage. The `print_entropy_dry_run` function in `src/stats.py` displays these statistics, ordering directories by potential savings and noting those below the configured threshold.

Global projections accumulate the total logical bytes of candidate directories into `entropy_projected_original_bytes` and the estimated post-compression size into `entropy_projected_compressed_bytes`, both fields of `CompressionStats` in `src/stats.py`. At the end of a dry run, `print_entropy_dry_run` outputs a summary of these projections using `_format_summary_size` (also in `src/stats.py`), providing an upper bound on potential disk space recovery.

## Live compression runs

During active compression, the program measures actual results. The `CompressionStats` dataclass in `src/stats.py` maintains running totals for the logical size of compressed files (`total_original_size`), their reported on-disk size (`total_compressed_size`), and the logical size of skipped files (`total_skipped_size`).

The compression executor updates these figures. It records the logical size before compression and the NTFS-reported size afterwards. The difference represents the space saved.

Files skipped by `should_compress_file` in `src/file_utils.py`—due to existing compression, small size, or exclusion rules—are counted separately. The `record_file_skip` method of `CompressionStats` in `src/stats.py` increments the skipped file count and adds the file's logical size to the skipped total. To maintain accounting consistency, it also adds a size hint to the compressed total. Specific counters track reasons for skipping, such as file extension or prior compression.

## Directory totals

The summary reports directory sizes before and after compression. The "before" size is the sum of logical sizes for all compressed files, excluding skipped items. The "after" size is the sum of their NTFS-reported compressed sizes, which implicitly accounts for sparse allocation, metadata, and cluster rounding.

The `print_compression_summary` function in `src/stats.py` derives the final metrics from these totals: original size in megabytes, total space saved, and the overall compression ratio. If no files were compressed, the summary notes that the directory may already be optimized.

## Implementation details

Size thresholds prevent inefficient operations; `should_compress_file` in `src/file_utils.py` ignores files smaller than `MIN_COMPRESSIBLE_SIZE` (defined in `src/config.py`) to avoid overhead from metadata and cluster rounding.

When skipping files where the exact compressed size is unknown, `record_file_skip` in `src/stats.py` uses provided size hints or falls back to the original size to keep global totals consistent.

Output formatting is centralized in `_format_sample_bytes` and `_format_summary_size` in `src/stats.py`, ensuring readable units (megabytes or gigabytes) across all reports.
